{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPrdXbJDEPYElHEyx6jgEwY"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"id":"etuSA7-Ch4S5","executionInfo":{"status":"ok","timestamp":1770022107329,"user_tz":-540,"elapsed":5531,"user":{"displayName":"tonyntrish","userId":"03121686291349343937"}}},"outputs":[],"source":["# 1. 라이브러리 설치\n","!pip install -q -U google-generativeai\n","\n","# 2. 라이브러리 임포트 및 API 키 설정\n","import google.generativeai as genai\n","from google.colab import userdata\n","\n","# 코랩 보안 비밀에서 키 가져오기\n","GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n","genai.configure(api_key=GOOGLE_API_KEY)"]},{"cell_type":"code","source":["# 3. 모델 초기화\n","model = genai.GenerativeModel('models/gemini-flash-latest')\n","\n","# 4. 질문 던지기\n","response = model.generate_content(\"코랩에서 제미나이 api frrr tier 모델 종류 알려줘.\")\n","\n","# 5. 결과 출력\n","print(response.text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"ffJvTuyjigov","executionInfo":{"status":"ok","timestamp":1770022627298,"user_tz":-540,"elapsed":9460,"user":{"displayName":"tonyntrish","userId":"03121686291349343937"}},"outputId":"81cfa177-5c9f-422a-b2ab-af87603d2c26"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["코랩에서 Gemini API를 사용하여 액세스할 수 있는 주요 모델 종류는 다음과 같습니다.\n","\n","Gemini API를 사용할 때, 일반적으로 **성능과 속도에 따라** 모델이 나뉘며, 가장 최신이자 추천되는 모델들은 **Gemini 2.5 계열**입니다.\n","\n","## 1. Gemini 2.5 계열 (현재 권장되는 모델)\n","\n","현재 Gemini API를 통해 사용할 수 있는 가장 강력하고 권장되는 모델들입니다.\n","\n","| 모델 이름 (API 호출 시 사용) | 특징 | 사용 용도 |\n","| :--- | :--- | :--- |\n","| **`gemini-2.5-flash`** | **가장 빠르고 효율적인 모델.** 일반적인 텍스트 생성, 요약, 분류, 가벼운 대화 등 대부분의 작업에 적합합니다. **API에서 기본 모델로 가장 많이 추천됩니다.** | 빠른 응답 속도가 필요한 웹 애플리케이션, 채팅봇, 짧은 코드 생성 등. |\n","| **`gemini-2.5-pro`** | **가장 강력한 추론 능력을 가진 모델.** 매우 복잡한 문제 해결, 정교한 코딩, 깊은 이해가 필요한 분석 작업 등에 사용됩니다. | 복잡한 과학/수학 문제, 장문의 전문 분석, 다단계 추론이 필요한 작업. |\n","\n","---\n","\n","## 2. Gemini 1.5 계열 (롱 컨텍스트용)\n","\n","Gemini 1.5 계열은 대규모 컨텍스트 창(Context Window)을 지원하는 것이 특징입니다.\n","\n","| 모델 이름 (API 호출 시 사용) | 특징 | 사용 용도 |\n","| :--- | :--- | :--- |\n","| **`gemini-1.5-flash`** | 대규모 데이터 처리(수십만 토큰)가 가능하며, 동시에 빠른 응답 속도를 제공합니다. | 방대한 양의 문서 또는 코드 베이스 검색, 전체 비디오/오디오 파일 분석 등. |\n","\n","---\n","\n","## 3. 예시: 코랩에서 모델 호출 시 사용법\n","\n","코랩에서 `google-genai` 라이브러리를 사용하여 모델을 호출할 때 모델 이름을 지정하게 됩니다.\n","\n","```python\n","import os\n","from google import genai\n","\n","# API 키 설정 (보안상 환경 변수로 설정하는 것을 권장)\n","# client = genai.Client(api_key=\"YOUR_API_KEY\") \n","client = genai.Client() # 환경 변수가 설정되어 있으면 키 없이 초기화 가능\n","\n","# 1. 가장 빠르고 효율적인 모델 사용\n","model_flash = \"gemini-2.5-flash\"\n","response_flash = client.models.generate_content(\n","    model=model_flash,\n","    contents=\"Gemini 2.5 Flash에 대해 간략히 설명해 주세요.\"\n",")\n","print(f\"Flash 응답: {response_flash.text}\")\n","\n","# 2. 가장 강력한 추론 모델 사용\n","model_pro = \"gemini-2.5-pro\"\n","response_pro = client.models.generate_content(\n","    model=model_pro,\n","    contents=\"양자 컴퓨터의 작동 원리를 설명해 주세요.\"\n",")\n","print(f\"Pro 응답: {response_pro.text}\")\n","```\n","\n","### ❗ 참고: 'Free Tier' (무료 등급) 관련\n","\n","사용자가 문의하신 'frrr tier'가 **\"무료 등급(Free Tier)\"**을 의미한다면, Gemini API는 일반적으로 API 키를 발급받으면 일정량의 무료 사용량(Usage Credit)을 제공합니다. 이 무료 사용량 내에서는 위에서 언급된 모든 모델(특히 `gemini-2.5-flash`)을 사용할 수 있습니다. 다만, 사용량이 해당 크레딧을 초과하거나 매우 큰 모델(예: 1.5 Pro)의 대용량 컨텍스트 창을 사용할 경우 비용이 발생할 수 있습니다.\n","\n","**`gemini-2.5-flash`**는 가장 빠르고 비용 효율적이기 때문에, 테스트 및 일반적인 무료 사용 환경에서 가장 권장되는 모델입니다.\n"]}]},{"cell_type":"code","source":["for m in genai.list_models():\n","    if 'generateContent' in m.supported_generation_methods:\n","        print(m.name)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":568},"id":"KRtufrLKiweH","executionInfo":{"status":"ok","timestamp":1770022178734,"user_tz":-540,"elapsed":1136,"user":{"displayName":"tonyntrish","userId":"03121686291349343937"}},"outputId":"b2b6c69f-74a9-4bed-f644-64b84a6e8e6e"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["models/gemini-2.5-flash\n","models/gemini-2.5-pro\n","models/gemini-2.0-flash\n","models/gemini-2.0-flash-001\n","models/gemini-2.0-flash-exp-image-generation\n","models/gemini-2.0-flash-lite-001\n","models/gemini-2.0-flash-lite\n","models/gemini-exp-1206\n","models/gemini-2.5-flash-preview-tts\n","models/gemini-2.5-pro-preview-tts\n","models/gemma-3-1b-it\n","models/gemma-3-4b-it\n","models/gemma-3-12b-it\n","models/gemma-3-27b-it\n","models/gemma-3n-e4b-it\n","models/gemma-3n-e2b-it\n","models/gemini-flash-latest\n","models/gemini-flash-lite-latest\n","models/gemini-pro-latest\n","models/gemini-2.5-flash-lite\n","models/gemini-2.5-flash-image\n","models/gemini-2.5-flash-preview-09-2025\n","models/gemini-2.5-flash-lite-preview-09-2025\n","models/gemini-3-pro-preview\n","models/gemini-3-flash-preview\n","models/gemini-3-pro-image-preview\n","models/nano-banana-pro-preview\n","models/gemini-robotics-er-1.5-preview\n","models/gemini-2.5-computer-use-preview-10-2025\n","models/deep-research-pro-preview-12-2025\n"]}]}]}